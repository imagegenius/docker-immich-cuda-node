---
# project information
project_name: immich-cuda-node
project_url: "https://github.com/imagegenius/docker-immich-cuda-node"
project_logo: "https://avatars.githubusercontent.com/u/121947548?s=200&v=4"
project_blurb: "immich-cuda-node is a remote machine leaning worker for Immich"
project_github_repo_url: "https://github.com/imagegenius/docker-{{ project_name }}"
project_blurb_optional_extras_enabled: false

# supported architectures
available_architectures:
  - { arch: "{{ arch_x86_64 }}", tag: "amd64-latest" }

# container parameters
common_param_env_vars_enabled: true
param_container_name: "{{ project_name }}"
param_usage_include_net: false
param_usage_include_env: false
param_usage_include_vols: true
param_volumes:
  - { vol_path: "/config", vol_host_path: "path_to_appdata", desc: "Package cache, this folder could potentially use +5GB!" }
  - { vol_path: "/photos", vol_host_path: "path_to_photos", desc: "Contains all the photos uploaded to Immich" }
param_usage_include_ports: true
param_ports:
  - { external_port: "3003", internal_port: "3003", port_desc: "WebUI Port" }
param_device_map: false
cap_add_param: false

# optional container parameters
opt_param_usage_include_env: false
opt_param_usage_include_vols: false
opt_param_usage_include_ports: false
opt_param_device_map: false
opt_cap_add_param: false
optional_block_1: false

# disable unraid template till container works
unraid_template: false

# application setup block
app_setup_block_enabled: true
app_setup_block: |
  To start, you will need to modify your Immich instance by disabling its built-in machine learning service.

  On your main Immich container, set the necessary environment variables:

  - Set `CUDA_ACCELERATION` to `false`. This will disable CUDA acceleration.
  - Set `IMMICH_MACHINE_LEARNING_URL` to `http://<ip>:3003`.

  Replace `<ip>` with the IP address of your immich-cuda-node container/host.

  ## Enabling GPU Acceleration with this container

  To start this image with GPU support, you need to modify your Docker settings.

  If you're using the Docker CLI, add the `--gpus=all` flag to your command.

  ```sh
  docker run --gpus=all ...
  ```

  If you're using Docker Compose, add the following under your service:

  ```yaml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
  ```

  This will reserve all available GPUs for your container, using the NVIDIA driver.

# changelog
changelogs:
  - { date: "25.05.23:", desc: "Initial Release." }
